---
title: "STAT4255 Homework 1"
author: "Jack Bienvenue"
date: "September 18th, 2024"
format: html
---

Hello Dr. Gu! This is Jack Bienvenue. I'm looking forward to a great semester of learning about Statistical Learning. This is generated with a Quarto Document in VSCode. Below are the necessary exercises for this homework assignment.


``` python
#We'll begin by importing necessary packages:
import pandas as pd
```

# Exercise 1 (ISLP Chapter 2 Exercise 2):
Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.

### (a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

This scenario is a regression problem. We see that we are using several variables which are continuous, quasi-continuous, or categorical such as:

- Profit
- Number of employees
- Industry 

Based on the setup of the problem, we know that **CEO salary** is the response variable we are looking to explain. 

While this problem could have applications for prediction, we are looking to make *inferences* about which factors affect CEO salary based upon our explanatory variable. Regression analysis provides many methods to evaluate the influence of predictors on a response.

Here, we have $n = 500$ for the number of firms in the dataset. We are working with $p = 3$ predictors, listed above. 

### (b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.

This problem would fall under the category of **classification problems**. This is made clear by the fact that our response variable is not continuous in nature by any means -- instead, the response is simply **success** or **failure**, two classes. 

Here, we are heavily vested in the idea of **prediction**. We are building a model to inform our business decision. We are assuming that there is an inference-strength connection between our predictors and response and we are using this to predict future success.

Here we are working with $n = 20$ for the number of similar products and $p = 13$ for the number of predictors considered. 

### (c) We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.

Here, we are working with another regression problem. The percentage change in an exchange rate is a continuous variable. 

Here, prediction is the certain goal of our efforts. There can be great arbitrage profits to be made by playing with exchange rates well. For market modeling, prediction is nearly always the goal.

Here we have $n = 52$, for the number of weeks in the year (assuming there are no weeks off for exchange rate calculations), and $p = 3$, the percentage changes in the US, UK, and German markets. 

# Exercise 2 (ISLP Chapter 2 Exercise 7):
The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.

| Obs. | X1 | X2 | X3 | Y     |
|------|----|----|----|-------|
| 1    | 0  | 3  | 0  | Red   |
| 2    | 2  | 0  | 0  | Red   |
| 3    | 0  | 1  | 3  | Red   |
| 4    | 0  | 1  | 2  | Green |
| 5    | -1 | 0  | 1  | Green |
| 6    | 1  | 1  | 1  | Red   |

Suppose we wish to use this data set to make a prediction for Y when X1 = X2 = X3 = 0 using K-nearest neighbors.

### (a) Compute the Euclidean distance between each observation and the test point, $X1 = X2 = X3 = 0$.

Let's use a three-dimensional space where we model coordinates as $(X_1,X_2,X_3)$. We will obtain the following distances using 3-dimensional Euclidean distance formula: $$d = \sqrt{(X_1 - X_{\text{test}})^2 + (X_2 - X_{\text{test}})^2 + (X_3 - X_{\text{test}})^2}$$. 

Making use of this formula, we can amend our table in the following way:

| Obs. | X1 | X2 | X3 | Y     | Distance from test point|
|------|----|----|----|-------|-------------------------|
| 1    | 0  | 3  | 0  | Red   |            3            |
| 2    | 2  | 0  | 0  | Red   |            2            |
| 3    | 0  | 1  | 3  | Red   |           3.162         |
| 4    | 0  | 1  | 2  | Green |           2.236         |
| 5    | -1 | 0  | 1  | Green |           1.414         |
| 6    | 1  | 1  | 1  | Red   |           1.732         |


### (b) What is our prediction with K = 1? Why?

For $K = 1$ nearest neighbors, our test point $(0,0,0)$ is closest to the point for observation 5, $(-1,0,1)$, and since this is the only neighbor we are taking into account, and its response value is $\textbf{Green}$, we will take our response value for test point $(0,0,0)$ to be $\textbf{Green}$.

### (c) What is our prediction with K = 3? Why?

For $K = 3$ nearest neighbors, test point $(0,0,0)$ has nearest neighbors:

| Obs. | X1 | X2 | X3 | Y     | Distance from test point|
|------|----|----|----|-------|-------------------------|
| 5    | -1 | 0  | 1  | Green |           1.414         |
| 6    | 1  | 1  | 1  | Red   |           1.732         |
| 2    | 2  | 0  | 0  | Red   |            2            |

Since we find that the majority of our neighbors have response $Y$ value as $\textbf{Red}$, we will identify our test point as $\textbf{Red}$.


### (d) If the Bayes decision boundary in this problem is highly non- linear, then would we expect the best value for K to be large or small? Why?

For highly non-linear Bayes decision boundary, we would select a smaller $\textbf{K}$ for the modeling of our scenario given a choice. How come? The addition of nearest neighbors has something a smoothing effect on the decision boundary. Smaller $\textbf{K}$ values will allow for smaller nuances in the decision boundary to be present, while these might be smoothed out with a larger $\textbf{K}$. This is important for non-linear data because very high relative $\textbf{K}$ values could appear to fit a decision boundary to data that looks more linear, or simpler in general, potenially not capturing the nature of the data. 

# Exercise 3 (ISLP Chapter 2 Exercise 8):

This exercise relates to the College data set, which can be found in the file College.csv on the book website. It contains a number of variables for 777 different universities and colleges in the US. The variables are:
• Private : Public/private indicator
• Apps : Number of applications received
• Accept : Number of applicants accepted
• Enroll : Number of new students enrolled
• Top10perc : New students from top 10 % of high school class • Top25perc : New students from top 25 % of high school class • F.Undergrad : Number of full-time undergraduates
• P.Undergrad : Number of part-time undergraduates
• Outstate : Out-of-state tuition
• Room.Board : Room and board costs
• Books : Estimated book costs
• Personal : Estimated personal spending
• PhD : Percent of faculty with Ph.D.s
• Terminal : Percent of faculty with terminal degree
• S.F.Ratio : Student/faculty ratio
• perc.alumni : Percent of alumni who donate
• Expend : Instructional expenditure per student
• Grad.Rate : Graduation rate
Before reading the data into Python, it can be viewed in Excel or a text editor.
### (a) Use the pd.read_csv() function to read the data into Python. Call the loaded data college. Make sure that you have the directory set to the correct location for the data.

### (b) Look at the data used in the notebook by creating and running a new cell with just the code college in it. You should notice that the first column is just the name of each university in a column named something like Unnamed: 0. We don’t really want pandas to treat this as data. However, it may be handy to have these names for later. Try the following commands and similarly look at the resulting data frames:


college2 = pd.read_csv('College.csv', index_col=0) 

college3 = college.rename({'Unnamed: 0': 'College'}, axis=1) 
college3 = college3.set_index('College')

This has used the first column in the file as an index for the data frame. This means that pandas has given each row a name corresponding to the appropriate university. Now you should see that the first data column is Private. Note that the names of the colleges appear on the left of the table. We also introduced a new python object above: a dictionary, which is specified by (key, value) pairs. Keep your modified version of the data with the following:
college = college3

### (c) Use the describe() method of to produce a numerical summary of the variables in the data set.
dictionary

### (d) Use the pd.plotting.scatter_matrix() function to produce a scatterplotmatrixofthefirstcolumns[Top10perc, Apps, Enroll]. Recall that you can reference a list C of columns of a data frame A using A[C].

### (e) Use the boxplot() method of college to produce side-by-side boxplots of Outstate versus Private.

### (f) Create a new qualitative variable, called Elite, by binning the Top10perc variable into two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50%.
Use the value_counts() method of college['Elite'] to see how many elite universities there are. Finally, use the boxplot() method again to produce side-by-side boxplots of Outstate versus Elite.
   college['Elite'] = pd.cut(college['Top10perc'], [0,0.5,1],
labels=['No', 'Yes'])

### (g) Use the plot.hist() method of college to produce some his- tograms with differing numbers of bins for a few of the quanti- tative variables. The command plt.subplots(2, 2) may be use- ful: it will divide the plot window into four regions so that four plots can be made simultaneously. By changing the arguments you can divide the screen up in other combinations.

### (h) Continue exploring the data, and provide a brief summary of what you discover.

# Exercise 4 (ISLP Chapter 2 Exercise 8):

### Question 1
### Question 2
### Question 3
### Question 4
### Question 5
